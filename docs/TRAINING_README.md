# MossFormer2 Training Guide

å®Œæ•´å¤ç°è®ºæ–‡ "MossFormer2: Combining Transformer and RNN-Free Recurrent Network" çš„è®­ç»ƒæµç¨‹ã€‚

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå®‰è£…](#ç¯å¢ƒå®‰è£…)
2. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
3. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
4. [å¼€å§‹è®­ç»ƒ](#å¼€å§‹è®­ç»ƒ)
5. [ç›‘æ§è®­ç»ƒ](#ç›‘æ§è®­ç»ƒ)
6. [è¯„ä¼°æ¨¡å‹](#è¯„ä¼°æ¨¡å‹)
7. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ ç¯å¢ƒå®‰è£…

### æ–¹æ³•1: ä½¿ç”¨pipå®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
conda create -n mossformer2 python=3.8
conda activate mossformer2

# å®‰è£…PyTorch (æ ¹æ®ä½ çš„CUDAç‰ˆæœ¬é€‰æ‹©)
# CUDA 11.3
pip install torch==1.12.0+cu113 torchaudio==0.12.0+cu113 --extra-index-url https://download.pytorch.org/whl/cu113

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

### æ–¹æ³•2: ä½¿ç”¨SpeechBrainæ¡†æ¶ï¼ˆæ¨èï¼‰

```bash
# å…‹éš†å¹¶å®‰è£…SpeechBrain
git clone https://github.com/speechbrain/speechbrain.git
cd speechbrain
pip install -r requirements.txt
pip install -e .
```

---

## ğŸ“Š æ•°æ®å‡†å¤‡

### æ”¯æŒçš„æ•°æ®é›†

1. **WSJ0-2mix / WSJ0-3mix** (è®ºæ–‡ä¸»è¦ä½¿ç”¨)
2. **Libri2Mix**
3. **WHAM! / WHAMR!**

### WSJ0-2mix æ•°æ®å‡†å¤‡

```bash
# 1. ä¸‹è½½WSJ0æ•°æ®é›†ï¼ˆéœ€è¦LDCæˆæƒï¼‰
# https://catalog.ldc.upenn.edu/LDC93S6A
# https://catalog.ldc.upenn.edu/LDC94S13A

# 2. ç”ŸæˆWSJ0-2mixæ•°æ®é›†
git clone https://github.com/mpariente/asteroid.git
cd asteroid/egs/wsj0-mix/generate_data
./create_wsj_mix.sh /path/to/wsj0 /path/to/output/wsj0-2mix 8000 2

# æ•°æ®é›†ç»“æ„åº”è¯¥å¦‚ä¸‹:
# wsj0-2mix/
#   â”œâ”€â”€ train/
#   â”‚   â”œâ”€â”€ mix/
#   â”‚   â”œâ”€â”€ s1/
#   â”‚   â””â”€â”€ s2/
#   â”œâ”€â”€ val/
#   â”‚   â”œâ”€â”€ mix/
#   â”‚   â”œâ”€â”€ s1/
#   â”‚   â””â”€â”€ s2/
#   â””â”€â”€ test/
#       â”œâ”€â”€ mix/
#       â”œâ”€â”€ s1/
#       â””â”€â”€ s2/
```

### Libri2Mix æ•°æ®å‡†å¤‡

```bash
# ä½¿ç”¨å®˜æ–¹è„šæœ¬ç”Ÿæˆ
git clone https://github.com/JorisCos/LibriMix.git
cd LibriMix
./scripts/generate_librimix.sh /path/to/librispeech /path/to/output/libri2mix

# æˆ–è€…ä¸‹è½½é¢„ç”Ÿæˆçš„æ•°æ®é›†
# https://zenodo.org/record/3871592
```

---

## âš™ï¸ é…ç½®è¯´æ˜

ç¼–è¾‘ `configs/train_mossformer2.yaml`:

```yaml
# 1. ä¿®æ”¹æ•°æ®è·¯å¾„
data_folder: /path/to/your/wsj0-2mix  # æ”¹ä¸ºä½ çš„æ•°æ®é›†è·¯å¾„

# 2. é€‰æ‹©æ•°æ®é›†ç±»å‹
dataset: wsj0-2mix  # wsj0-2mix, wsj0-3mix, libri2mix, wham, whamr
num_spks: 2  # è¯´è¯äººæ•°é‡

# 3. è®­ç»ƒå‚æ•°ï¼ˆè®ºæ–‡é…ç½®ï¼Œå»ºè®®ä¸æ”¹ï¼‰
N_epochs: 200
batch_size: 1  # å¦‚æœæ˜¾å­˜è¶³å¤Ÿå¯ä»¥æ”¹ä¸º2æˆ–4
lr: 0.000015  # 15e-5
gradient_clip: 5.0
lr_decay_epoch: 85
lr_decay_factor: 0.5

# 4. æ¨¡å‹é…ç½®ï¼ˆå®Œæ•´ç‰ˆ MossFormer2ï¼‰
encoder_kernel_size: 16
encoder_embedding_dim: 512
num_mossformer_layer: 24
# è¿™ä¸ªé…ç½®å¯¹åº”è®ºæ–‡ä¸­çš„ 55.7M å‚æ•°

# 5. åŠ¨æ€æ··åˆï¼ˆè®ºæ–‡è®¾ç½®ï¼‰
use_dynamic_mixing: True  # Libri2Mixè®¾ä¸ºFalse
```

### å°ç‰ˆæœ¬é…ç½® (MossFormer2-S)

å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥ä½¿ç”¨å°ç‰ˆæœ¬ï¼ˆ37.8Må‚æ•°ï¼‰:

```yaml
encoder_embedding_dim: 384
mossformer_sequence_dim: 384
num_mossformer_layer: 25
```

---

## ğŸš€ å¼€å§‹è®­ç»ƒ

### åŸºæœ¬è®­ç»ƒå‘½ä»¤

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python train.py --config configs/train_mossformer2.yaml

# æŒ‡å®šGPU
CUDA_VISIBLE_DEVICES=0 python train.py --config configs/train_mossformer2.yaml
```

### ä»æ–­ç‚¹æ¢å¤è®­ç»ƒ

è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œé‡æ–°è¿è¡Œç›¸åŒå‘½ä»¤å³å¯æ¢å¤ï¼š

```bash
# è‡ªåŠ¨ä» latest_checkpoint.pt æ¢å¤
python train.py --config configs/train_mossformer2.yaml
```

### å¤šGPUè®­ç»ƒï¼ˆå¯é€‰ï¼‰

```bash
# ä½¿ç”¨ DataParallel (ç®€å•ä½†æ•ˆç‡è¾ƒä½)
# ä¿®æ”¹ train.py ä¸­çš„æ¨¡å‹åˆå§‹åŒ–:
# self.model = nn.DataParallel(self.model)

# æˆ–ä½¿ç”¨ DistributedDataParallel (æ¨è)
python -m torch.distributed.launch --nproc_per_node=4 train.py --config configs/train_mossformer2.yaml
```

---

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### ä½¿ç”¨TensorBoard

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir results/mossformer2/1234/logs --port 6006

# åœ¨æµè§ˆå™¨æ‰“å¼€: http://localhost:6006
```

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f results/mossformer2/1234/train_log.txt

# æŸ¥çœ‹æœ€è¿‘10è¡Œ
tail -n 10 results/mossformer2/1234/train_log.txt
```

### æ£€æŸ¥ç‚¹ä½ç½®

```
results/mossformer2/1234/save/
â”œâ”€â”€ latest_checkpoint.pt  # æœ€æ–°æ£€æŸ¥ç‚¹
â””â”€â”€ best_checkpoint.pt    # æœ€ä½³éªŒè¯é›†æ£€æŸ¥ç‚¹
```

---

## ğŸ“Š è¯„ä¼°æ¨¡å‹

åˆ›å»ºè¯„ä¼°è„šæœ¬ `evaluate.py`:

```python
import torch
from train import MossFormer2Trainer
from loss import si_sdr_improvement

def evaluate():
    # åŠ è½½è®­ç»ƒå™¨
    trainer = MossFormer2Trainer('configs/train_mossformer2.yaml')

    # åŠ è½½æœ€ä½³æ£€æŸ¥ç‚¹
    checkpoint_path = 'results/mossformer2/1234/save/best_checkpoint.pt'
    trainer.load_checkpoint(checkpoint_path)

    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    trainer.model.eval()
    total_si_sdri = 0.0
    num_samples = 0

    with torch.no_grad():
        for batch in trainer.test_loader:
            mixture = batch['mixture'].to(trainer.device)
            sources = [s.to(trainer.device) for s in batch['sources']]

            # æ¨ç†
            estimated = trainer.model(mixture)

            # è®¡ç®— SI-SDRi
            for i in range(len(sources)):
                si_sdri = si_sdr_improvement(estimated[i], sources[i], mixture)
                total_si_sdri += si_sdri.mean().item()

            num_samples += 1

    avg_si_sdri = total_si_sdri / (num_samples * len(sources))
    print(f"Test SI-SDRi: {avg_si_sdri:.2f} dB")

if __name__ == '__main__':
    evaluate()
```

è¿è¡Œè¯„ä¼°:

```bash
python evaluate.py
```

---

## ğŸ¯ é¢„æœŸç»“æœ

æ ¹æ®è®ºæ–‡ Table 2ï¼Œåœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„é¢„æœŸ SI-SDRi ç»“æœï¼š

| æ•°æ®é›† | SI-SDRi (dB) |
|--------|-------------|
| WSJ0-2mix | 24.1 |
| WSJ0-3mix | 22.2 |
| Libri2Mix | 21.7 |
| WHAM! | 18.1 |
| WHAMR! | 17.0 |

**æ³¨æ„**: è¾¾åˆ°è¿™äº›ç»“æœéœ€è¦ï¼š
- å®Œæ•´è®­ç»ƒ200ä¸ªepochs
- æ­£ç¡®çš„æ•°æ®é¢„å¤„ç†
- è®ºæ–‡ä¸­çš„åŠ¨æ€æ··åˆè®¾ç½®
- å¯èƒ½éœ€è¦å¤šæ¬¡è¿è¡Œå–æœ€ä½³ç»“æœ

---

## â“ å¸¸è§é—®é¢˜

### Q1: CUDA Out of Memory

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# 1. å‡å°batch size
batch_size: 1  # å·²ç»æ˜¯æœ€å°äº†

# 2. ä½¿ç”¨å°ç‰ˆæœ¬æ¨¡å‹
encoder_embedding_dim: 384
num_mossformer_layer: 25

# 3. å‡å°‘éŸ³é¢‘é•¿åº¦
segment_length: 3.0  # ä»4ç§’æ”¹ä¸º3ç§’

# 4. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§batch
# ä¿®æ”¹train.pyï¼Œæ¯Næ­¥æ›´æ–°ä¸€æ¬¡
```

### Q2: è®­ç»ƒå¤ªæ…¢

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. å¢åŠ num_workers
num_workers: 8  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´

# 2. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
# åœ¨train.pyä¸­æ·»åŠ :
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()

# 3. å‡å°‘éªŒè¯é¢‘ç‡
# æ¯5ä¸ªepochéªŒè¯ä¸€æ¬¡è€Œä¸æ˜¯æ¯ä¸ªepoch
```

### Q3: SI-SDRiå¤ªä½

**æ£€æŸ¥æ¸…å•**:
- âœ“ æ•°æ®é›†æ˜¯å¦æ­£ç¡®ç”Ÿæˆï¼Ÿ
- âœ“ é‡‡æ ·ç‡æ˜¯å¦åŒ¹é…ï¼ˆ8kHzï¼‰ï¼Ÿ
- âœ“ åŠ¨æ€æ··åˆæ˜¯å¦å¯ç”¨ï¼Ÿ
- âœ“ å­¦ä¹ ç‡è°ƒåº¦æ˜¯å¦æ­£ç¡®ï¼Ÿ
- âœ“ æ˜¯å¦è®­ç»ƒè¶³å¤Ÿçš„epochsï¼Ÿ

### Q4: å¦‚ä½•ä½¿ç”¨16kHzæ•°æ®ï¼Ÿ

```yaml
# ä¿®æ”¹é…ç½®
sample_rate: 16000
encoder_kernel_size: 16  # ä¿æŒä¸å˜æˆ–è°ƒæ•´ä¸º32

# æ³¨æ„: è®ºæ–‡ä½¿ç”¨8kHzï¼Œ16kHzå¯èƒ½éœ€è¦é‡æ–°è°ƒæ•´å‚æ•°
```

---

## ğŸ“ è®­ç»ƒæ£€æŸ¥æ¸…å•

å¼€å§‹è®­ç»ƒå‰ç¡®è®¤ï¼š

- [ ] æ•°æ®é›†å·²æ­£ç¡®ä¸‹è½½å’Œç”Ÿæˆ
- [ ] é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„å·²ä¿®æ”¹
- [ ] å·²å®‰è£…æ‰€æœ‰ä¾èµ–ï¼ˆ`pip install -r requirements.txt`ï¼‰
- [ ] GPUæ˜¾å­˜è¶³å¤Ÿï¼ˆå»ºè®®32GB V100æˆ–ä»¥ä¸Šï¼‰
- [ ] ç¡¬ç›˜ç©ºé—´è¶³å¤Ÿï¼ˆæ£€æŸ¥ç‚¹æ–‡ä»¶çº¦2-3GBï¼‰
- [ ] å·²è®¾ç½®æ­£ç¡®çš„CUDA_VISIBLE_DEVICES

---

## ğŸ”— å‚è€ƒèµ„æº

- è®ºæ–‡: [arXiv:2312.11825](https://arxiv.org/abs/2312.11825)
- SpeechBrain: https://github.com/speechbrain/speechbrain
- WSJ0-mixç”Ÿæˆ: https://github.com/mpariente/asteroid
- LibriMix: https://github.com/JorisCos/LibriMix

---

## ğŸ“§ é—®é¢˜åé¦ˆ

è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜å¯ä»¥ï¼š
1. æŸ¥çœ‹ä¸Šè¿°å¸¸è§é—®é¢˜éƒ¨åˆ†
2. æ£€æŸ¥è®­ç»ƒæ—¥å¿—å’ŒTensorBoard
3. ç¡®è®¤é…ç½®æ˜¯å¦ä¸è®ºæ–‡ä¸€è‡´

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ‰
